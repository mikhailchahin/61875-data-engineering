{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Una empresa llamada DBU que vende equipos deportivos al aire libre, \\\n",
    "tiene muchas ubicaciones diferentes y ha estado registrando las ventas de diferentes ubicaciones en varios productos.\\\n",
    "Quiere saber cuáles son sus mejores productos y vendedores para mejorar su rendimiento general_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_base:str = \"https://raw.githubusercontent.com/CoderContenidos/Data.Engineering/main/Semana%207/Tablas/\"\n",
    "tables:list[str]= [\n",
    "    \"countryregioncurrency.csv\",\n",
    "    \"currencyrate.csv\",\n",
    "    \"product.csv\",\n",
    "    \"productcategory.csv\",\n",
    "    \"productdescription.csv\",\n",
    "    \"productmodelproductdescriptionculture.csv\",\n",
    "    \"productreview.csv\",\n",
    "    \"productsubcategory.csv\",\n",
    "    \"salesorderdetail.csv\",\n",
    "    \"salesorderheader.csv\",\n",
    "    \"salesperson.csv\",\n",
    "    \"salesterritory.csv\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema:str = \"andru_ocatorres_coderhouse\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes con SQL Alchemy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [SQLAlchemy Documentation]( https://docs.sqlalchemy.org/en/20/intro.html#installation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando las librerias necesarias para hacer la conexion a la base\n",
    "from sqlalchemy import create_engine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# crea un objeto url para conectar con la warehouse\n",
    "username = os.getenv('REDSHIFT_USERNAME')\n",
    "password = os.getenv('REDSHIFT_PASSWORD')\n",
    "host = os.getenv('REDSHIFT_HOST')\n",
    "port = os.getenv('REDSHIFT_PORT', '5439')\n",
    "dbname = os.getenv('REDSHIFT_DBNAME')\n",
    "\n",
    "# Construct the connection URL\n",
    "connection_url = f\"postgresql+psycopg2://{username}:{password}@{host}:{port}/{dbname}\"\n",
    "db_engine = create_engine(connection_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificamos la conexion\n",
    "try:\n",
    "    with db_engine.connect() as connection:\n",
    "        print(\"Conexion creada\")\n",
    "except Exception as e:\n",
    "    print(f\"Conexion fallida: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import Table, Column, Integer, String, MetaData, exc , inspect, text\n",
    "\n",
    "\n",
    "# funcion para crear la tabla si es que no existe\n",
    "def create_table(table_name,df,db_engine):\n",
    "    schema:str = \"andru_ocatorres_coderhouse\"\n",
    "    metadata = MetaData(schema=schema)\n",
    "\n",
    "    columns = []\n",
    "    \n",
    "    for col_name, col_type in zip(df.columns, df.dtypes):\n",
    "        if pd.api.types.is_integer_dtype(col_type):\n",
    "            columns.append(Column(col_name, Integer))\n",
    "        elif pd.api.types.is_float_dtype(col_type):\n",
    "            columns.append(Column(col_name, String))  # Redshift doesn't have a specific float type\n",
    "        elif pd.api.types.is_string_dtype(col_type):\n",
    "            columns.append(Column(col_name, String))\n",
    "        elif pd.api.types.is_datetime64_any_dtype(col_type):\n",
    "            columns.append(Column(col_name, String))  # Storing datetime as string for simplicity\n",
    "        else:\n",
    "            raise TypeError(f\"Unsupported dtype: {col_type}\")\n",
    "    \n",
    "    Table(table_name, metadata, *columns)\n",
    "    metadata.create_all(db_engine)\n",
    "    print(f\"Tabla {table_name} creada con exito\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# funcion para la carga de cada dataset\n",
    "def upload_csv(**kwargs):\n",
    "    base_path = kwargs[\"base_path\"]\n",
    "    csv_file = kwargs[\"csv\"]\n",
    "    engine = kwargs[\"engine\"]\n",
    "    chunksize = kwargs[\"chunksize\"] \n",
    "\n",
    "    table_name = csv_file.split(\".\")[0]\n",
    "    print(f\"{csv_file} to be read\")\n",
    "\n",
    "    try:\n",
    "        chunk_iterator = pd.read_csv(base_path + csv_file, chunksize=chunksize)\n",
    "        create_table(table_name, next(chunk_iterator), engine)  \n",
    "        print(f\"Table {table_name} structure created\")\n",
    "\n",
    "        for chunk in chunk_iterator:\n",
    "            chunk.to_sql(table_name, engine, if_exists='append', index=False)\n",
    "            print(f\"Uploaded chunk with {len(chunk)} records\")\n",
    "\n",
    "        print(f\"Table {table_name} has been successfully populated\")\n",
    "        return 1\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"La carga de la tabla: {table_name} no se realizó con éxito\")\n",
    "        return 0\n",
    "    \n",
    "# function para crear views areas funcionales\n",
    "\n",
    "def upload_views(**kwargs):\n",
    "    engine = kwargs[\"engine\"]\n",
    "    queries = kwargs[\"queries\"]\n",
    "    schema = kwargs[\"schema\"]\n",
    "    \n",
    "    # Transformation\n",
    "    queries_to_view = {\n",
    "        name: f\"CREATE OR REPLACE VIEW public.{name} AS\\n{query}\"\n",
    "        for name, query in queries.items()\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        with engine.begin() as connection:\n",
    "            for name, view_query in queries_to_view.items():\n",
    "                connection.execute(text(view_query))\n",
    "                print(f\"View '{name}' has been created successfully\")\n",
    "\n",
    "        print(\"Transaction committed successfully\")\n",
    "        return 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to create view: {e}\")\n",
    "        # Rollback the transaction in case of error\n",
    "        engine.rollback()\n",
    "        return 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploaded_status = [upload_csv(base_path=url_base,chunksize=100_000,csv=table,engine=db_engine) for table in tables]\n",
    "uploaded_status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREGUNTAS A RESPONDER\n",
    "* _MEJORES PRODUCTOS -> TOP PRODUCTOS EN REVIEW | TOP PRODUCTOS MAS VENDIDOS_\n",
    "* _VENDEDORES CON PEOR VENTA -> TOP N PEORES VENDEDORES_\n",
    "* _Encontrar los cinco vendedores con mejor desempeño usando la columna salesytd (Sales, year-to-date). (Solo necesitamos conocer el businessentityid de cada vendedor, ya que esto identifica de forma única a cada uno)._\n",
    "* _Usando salesorderheader, buscar los 5 mejores vendedores que hicieron la mayor cantidad de ventas en el año más reciente (2014). (Hay una columna llamada subtotal; usarla). Las ventas que no tienen un vendedor asociado deben excluirse de los cálculos y producción final. Se deben incluir todos los pedidos que se realizaron dentro del año calendario 2014.\n",
    "Pista: Pueden usar la sintaxis '1970-01-01' para generar un punto de comparación en el tiempo._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_worst_sellerstr = \"\"\"\n",
    "\n",
    "\tSELECT \n",
    "\t\tsalespersonid \n",
    "\t,\tROUND(CAST(SUM(totaldue) AS NUMERIC),2) AS TOTAL_AMOUNT_SELLED\n",
    "\t,\tCOUNT(1) AS AMOUNT_OF_SALES\n",
    "\tFROM public.salesorderheader  \n",
    "\tGROUP BY salespersonid \n",
    "\tORDER BY \n",
    "\t\tTOTAL_AMOUNT_SELLED\n",
    "\tLIMIT 10;\n",
    "\"\"\"\n",
    "\n",
    "sql_top_10_best_sells:str = \"\"\"\n",
    "WITH TOP_BEST_SELLS AS\n",
    "(\tSELECT \n",
    "\t\tS.productid\n",
    "\t,\tCOUNT(1) AS PRODUCT_TOTAL\n",
    "\tFROM public.salesorderdetail  S\n",
    "\tGROUP BY \n",
    "\t\tS.productid\n",
    "),\n",
    "AGG_TABLE as (\n",
    "SELECT \n",
    "\tproductid\n",
    ",\tP.productmodelid\n",
    ",\tP.name\n",
    ",\tPRODUCT_TOTAL\n",
    "FROM TOP_BEST_SELLS\n",
    "LEFT JOIN \n",
    "\tpublic.product AS P\n",
    "\tUSING(productid)\n",
    "ORDER BY PRODUCT_TOTAL DESC\n",
    "LIMIT 10\n",
    ")\n",
    "SELECT \n",
    "\tAG.name\n",
    ",\tPD.description\n",
    ",\tAG.PRODUCT_TOTAL\n",
    "FROM productdescription PD\n",
    "INNER JOIN productmodelproductdescriptionculture AS PC USING(productdescriptionid)\n",
    "\n",
    "INNER JOIN AGG_TABLE  AS AG USING(productmodelid)\n",
    "WHERE PC.cultureid = 'en' ;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "sql_best_reviews:str = \"\"\"\n",
    "WITH producto_rating AS (\n",
    "         SELECT pv.productid,\n",
    "            p.productmodelid,\n",
    "            p.name,\n",
    "            avg(pv.rating) AS avg_rating,\n",
    "            count(1) AS total_reviews\n",
    "           FROM productreview pv\n",
    "             LEFT JOIN product p USING (productid)\n",
    "          GROUP BY pv.productid, p.name, p.productmodelid\n",
    "          ORDER BY (avg(pv.rating)) DESC\n",
    "        )\n",
    " SELECT pr.name,\n",
    "    pd.description,\n",
    "    pr.avg_rating,\n",
    "    pr.total_reviews\n",
    "   FROM productdescription pd\n",
    "     JOIN productmodelproductdescriptionculture pc USING (productdescriptionid)\n",
    "     JOIN producto_rating pr USING (productmodelid)\n",
    "  WHERE pc.cultureid = 'en'::text;\"\"\"\n",
    "\n",
    "sql_best_sales_person:str = \"\"\"\n",
    "SELECT \n",
    "   \tbusinessentityid\n",
    ",\tsalesytd\n",
    "FROM salesperson\n",
    "ORDER BY salesytd DESC\n",
    "LIMIT 5 \n",
    "\"\"\"\n",
    "sql_best_sales_person_2014:str = \"\"\"\n",
    "SELECT \n",
    "    salespersonid,\n",
    "    ROUND(SUM(subtotal)::NUMERIC, 2) AS total_sales\n",
    "FROM \n",
    "    salesorderheader\n",
    "WHERE \n",
    "    orderdate >= '2014-01-01'\n",
    "    AND salespersonid IS NOT NULL\n",
    "GROUP BY \n",
    "    salespersonid\n",
    "ORDER BY \n",
    "    total_sales DESC\n",
    "LIMIT 5;\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "queries_to_view = {    \n",
    "\t\"best_sales_person_2014_view\":sql_best_sales_person_2014,\n",
    "    \"best_sales_person_view\":sql_best_sales_person,\n",
    "    \"best_reviews_view\":sql_best_reviews,\n",
    "    \"best_sells_view\":sql_top_10_best_sells,\n",
    "    \"worst_sellers_view\" : sql_worst_sellerstr\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generar carga de vistas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_views(engine=db_engine,queries=queries_to_view, schema=schema)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes con Psycopg - Linux(Psycopg-binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Psycopg Documentation](https://www.psycopg.org/psycopg3/docs/basic/install.html#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2 as pg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genera un objeto connector\n",
    "conn = pg.connect(\n",
    "        user = os.getenv('REDSHIFT_USERNAME')\n",
    "    ,   password = os.getenv('REDSHIFT_PASSWORD')\n",
    "    ,   host = os.getenv('REDSHIFT_HOST')\n",
    "    ,   port = os.getenv('REDSHIFT_PORT', '5439')\n",
    "    ,   database = os.getenv('REDSHIFT_DBNAME')\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_creator(**kwargs):\n",
    "    connection = kwargs[\"connection\"]\n",
    "    queries = kwargs[\"queries\"]\n",
    "\n",
    "    try:\n",
    "        with connection.cursor() as cursor:\n",
    "            queries_to_view = {\n",
    "                name: f\"CREATE OR REPLACE VIEW public.{name} AS\\n{query}\"\n",
    "                for name, query in queries.items()\n",
    "            }\n",
    "\n",
    "            for name, view_query in queries_to_view.items():\n",
    "                cursor.execute(view_query)\n",
    "                print(f\"View '{name}' ha sido creada\")\n",
    "\n",
    "        # Commit the transaction outside of the cursor context manager\n",
    "        connection.commit()\n",
    "        print(\"Transaction committed successfully\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error '{e}' occurred\")\n",
    "        connection.rollback() \n",
    "\n",
    "    finally:\n",
    "        connection.close()\n",
    "        print(\"Connection closed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view_creator(connection=conn,queries=queries_to_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## psycopg2 vs SQLAlchemy\n",
    "\n",
    "| Feature         | psycopg2                                    | SQLAlchemy                                          |\n",
    "|-----------------|---------------------------------------------|-----------------------------------------------------|\n",
    "| Type            | Database adapter                            | ORM library and SQL toolkit                        |\n",
    "| Purpose         | Interact with PostgreSQL databases         | Interact with multiple database engines             |\n",
    "| Functionality   | Low-level interface for executing SQL commands, managing connections, handling transactions | ORM for mapping Python objects to database tables, SQL toolkit for query building |\n",
    "| Level of Abstraction | Low-level, requires writing SQL queries directly | High-level, provides abstraction over SQL queries, supports ORM |\n",
    "| Performance     | Known for efficiency and performance      | Offers flexibility and abstraction, may have slightly more overhead |\n",
    "| Suitability     | Developers comfortable with SQL, need direct control over PostgreSQL interactions | Developers preferring higher-level abstraction, multiple database support |\n",
    "| Learning Curve  | Easier for SQL-savvy developers            | Steeper due to ORM and higher-level abstraction    |\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
